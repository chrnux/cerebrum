#!/usr/bin/env python
# -*- coding: iso-8859-1 -*-

import re
import sys
import getopt
import cereconf

from Cerebrum import Errors
from Cerebrum import Account
from Cerebrum import Group
from Cerebrum.Utils import Factory

from Cerebrum.modules.dns import ARecord
from Cerebrum.modules.dns import CNameRecord
from Cerebrum.modules.dns import DnsOwner
from Cerebrum.modules.dns import HostInfo
from Cerebrum.modules.dns import IPNumber

db = Factory.get('Database')()
db.cl_init(change_program='import_dns')
co = Factory.get('Constants')(db)
sys.argv.extend(["--logger-level", "DEBUG"])
logger = Factory.get_logger("console")
ipnumber = IPNumber.IPNumber(db)
arecord = ARecord.ARecord(db)
cname = CNameRecord.CNameRecord(db)
dnsowner = DnsOwner.DnsOwner(db)
host = HostInfo.HostInfo(db)
mx_set = DnsOwner.MXSet(db)

# logger.setLevel(logger.debug)
header_splitter = r'^; AUTOGENERATED: do not edit below this line'
#default_mx = [(10, 'smtp'),
#              (33, 'ulrik')]
zone_postfix = '.uio.no.'

auto_hinfo_num = 0
name2host = {}
name2cname = {}
name2arecord_owner = {}
name2dns_owner = {}   # Populated for MX
# ip2id = {}
default_revmap = {}
mx_targets = {}

class FileParsers(object):
    def parse_hosts_file(self, fname):
        # We are only interested in any comments for the hosts
        # Example: 129.240.2.3     nissen  nissen.uio.no #  ds5000/240
        logger.info("parse_hosts_file(%s)" % fname)
        f = file(fname)
        ret = {}
        while 1:
            line = f.readline()
            if not line: break
            ip_nr, hostname, rest = line.split("\t",2)
            if rest.find('#') == -1:
                continue
            rest = rest[rest.find('#')+1:]
            rest = rest.strip()
            if not hostname[-1] == '.':
                hostname = hostname + zone_postfix
            ret[hostname] = rest
        return ret

    def prepare_parse_revmap(self, fname):
        logger.info("parse_revmap(%s)" % fname)
        self.f = file(fname)
        while 1:
            line = self.f.readline()
            if not line: break
            if re.search(header_splitter, line): break
        self.r_linecomment = re.compile('^\s*;')
        self.r_blank = re.compile(r'^\s*$')
        self.r_origin = re.compile(
            r'^\$ORIGIN\s+(\d+\.\d+\.\d+)\.IN-ADDR.arpa.', re.IGNORECASE)
        
    def next_revmap(self):
        while 1:
            line = self.f.readline()
            if not line: break
            line = line.rstrip()
            if self.r_blank.search(line):
                continue
            if self.r_linecomment.search(line):
                continue
            m = self.r_origin.match(line)
            if m is not None:
                t = m.group(1).split(".")
                t.reverse()
                self.origin = ".".join(t)
                logger.debug2("Origin: %s" % self.origin)
                continue
            lparts = line.split()
            if len(lparts) != 3:
                logger.warn("huh: %s" % line)
                continue
            if lparts[1] != 'PTR':
                logger.warn("huh: %s" % line)
                continue
            return "%s.%s" % (self.origin, lparts[0]), filter_name(lparts[2])

    def prepare_parse_zone_file(self, fname):
        logger.info("parse_zone_file(%s)" % fname)
        self.f = file(fname)
        while 1:
            line = self.f.readline()
            if not line: break
            if re.search(header_splitter, line): break

        self.r_linecomment = re.compile('^\s*;')
        self.r_contact = re.compile(';\s*(\S+):\s*contact\s*(\S+)')
        self.r_blank = re.compile(r'^\s*$')
        self.r_comment = re.compile('(.*);(.*)')

    def next_zone_entry(self):
        while 1:
            line = self.f.readline()
            if not line: break
            line = line.rstrip()
            if self.r_blank.search(line):
                continue
            # Line start with ; check for contact-comment
            if self.r_linecomment.search(line):
                m = self.r_contact.match(line)
                if m is not None:
                    logger.debug2("Contact: %s=%s" % (m.group(1), m.group(2)))
                    name = filter_name(m.group(1))
                    if not name[-1] == '.':
                        name = name + zone_postfix
                    return 'contact', name, m.group(2)
                continue
            comment = None
            if self.r_comment.search(line):
                m = self.r_comment.match(line)
                line = m.group(1)
                comment = m.group(2).strip()
            # split line on whitespace
            lparts = line.split()
            ttl = None
            if not line[0].isspace():  # continuation of previous owner
                self.owner = filter_name(lparts[0])
                lparts = lparts[1:]
            if lparts[0].isdigit():   # Check for TTL value
                ttl = lparts[0]
                lparts = lparts[1:]
            rectype = lparts[0]       # Get record type
            lparts = lparts[1:]
            logger.debug2("%s: r=%s, ttl=%s" % (line, rectype, ttl))
            if rectype == 'TXT':   # Find quoted part of line
                lparts = [ line[line.find('"')+1:-1], ]
            elif rectype in ('MX', 'CNAME', 'SRV'):
                lparts[-1] = filter_name(lparts[-1])   # remove .uio.no.
            return rectype, ttl, lparts, comment

class MergeRestart(Exception):
    pass
def parse_netgroups(fname):
    import pprint
    pp = pprint.PrettyPrinter(indent=4)

    f = file(fname)
    r_linecomment = re.compile(r'^\s*#')
    r_blank = re.compile(r'^\s*$')
    r_machine_member = re.compile(r'\(([^\)]+),-,[^\)]*\)')
    netgroups = {}
    for line in f.readlines():
        if r_blank.search(line) or r_linecomment.search(line):
            continue
        parts = line.split()
        main_ng = netgroups[parts[0]] = {'machines': [], 'netgroups': []}
        for p in parts[1:]:
            m = r_machine_member.match(p)
            if m:
                main_ng['machines'].append(m.group(1))
            else:
                main_ng['netgroups'].append(p)

    # Try to merge netgroups that had appended digits due to too long
    # lines
    r_digit = re.compile(r'^(.*\D+)(\d+)$')
    non_existent_bases = {}
    merged_netgroups = {}
    while True:
        try:
            order = netgroups.keys()
            order.sort()    # Makes reading the debug-log easier
            for k in order:
                m = r_digit.match(k)
                if m:
                    if netgroups.has_key(m.group(1)):
                        print "Merging ", (m.group(1), m.group(2))
                        netgroups[m.group(1)]['machines'].extend(
                            netgroups[k]['machines'])
                        netgroups[m.group(1)]['netgroups'].extend(
                            netgroups[k]['netgroups'])
                        del(netgroups[k])
                        merged_netgroups[k] = True
                        raise MergeRestart()
                    else:
                        # print "base non-existent: ",  (m.group(1), m.group(2))
                        non_existent_bases[m.group(1)] = True
                else:
                    # print k
                    pass
            break
        except MergeRestart:
            # OK, it could probably be done a better way, but it is
            # late, and I'm tired...
            pass
    for k in netgroups.keys():
        for m in merged_netgroups.keys():
            if m in netgroups[k]['netgroups']:
                netgroups[k]['netgroups'].remove(m)
    print "Non-existent bases found:", non_existent_bases.keys()
    #pp.pprint(netgroups)
    return netgroups

def ng_machine_filter(name):
    if len(name.split(".")) > 2:
        return name + "."
    return name + zone_postfix

def import_netgroups(fname):
    netgroups = parse_netgroups(fname)
    account = Account.Account(db)
    account.find_by_name(cereconf.INITIAL_ACCOUNTNAME)
    creator_id = account.entity_id
    group = Group.Group(db)
    # First define all netgroups
    groupname2id = {}
    for k in netgroups.keys():
        sys.stdout.write('g')
        sys.stdout.flush()
        names = [k]
        names.extend(netgroups[k]['netgroups'])
        for n in names:
            if groupname2id.has_key(n):
                continue
            group.clear()
            group.populate(creator_id=creator_id,
                           visibility=co.group_visibility_all,
                           name=n, description='machine netgroup %s' % n)
            group.write_db()
            group.add_spread(co.spread_uio_machine_netgroup)
            groupname2id[n] = group.entity_id

    # Then populate members
    dns_owner2id = {}
    for row in dnsowner.list():
        dns_owner2id[row['name']] = int(row['dns_owner_id'])
    for k in groupname2id.keys():
        sys.stdout.write('.')
        sys.stdout.flush()
        # Add group members
        group.clear()
        group.find(groupname2id[k])
        if not netgroups.has_key(k):
            print "Warning, no members for %s" % k
            continue
        for n in netgroups[k]['netgroups']:
            group.add_member(groupname2id[n],
                             co.entity_group,
                             co.group_memberop_union)
        # Add machine memebers
        machines = {}
        for n in netgroups[k]['machines']:
            n = ng_machine_filter(n)
            machines[n] = True
        for n in machines.keys():
            if not dns_owner2id.has_key(n):
                print "Warning, unknown member: %s" % n
                continue
            group.add_member(dns_owner2id[n],
                             co.entity_dns_owner,
                             co.group_memberop_union)
    db.commit()

def process_zone_file(fname):
    parser.prepare_parse_zone_file(fname)
    
    records = {}
    while True:
        dta = parser.next_zone_entry()
        if not dta:
            break
        rectype = dta[0]
        if rectype == 'contact':
            name, dest = dta[1:3]
            records.setdefault(name, {})['contact'] = dest
        elif rectype in ('HINFO', 'MX', 'TXT', 'A', 'CNAME', 'SRV'):
            ttl, lparts, comment = dta[1:4]
            if not records.has_key(parser.owner):
                records[parser.owner] = {}
            if comment:
                if rectype in ('A', 'CNAME'):
                    records[parser.owner]['comment'] = comment
                else:
                    logger.warn("Unexpected comment in %s" % str(dta))
            lparts.insert(0, ttl)
            records[parser.owner].setdefault(rectype, []).append(lparts)
        else:
            logger.warn("eh?: %s" % str(dta))
        # logger.debug("'%s' (%s) -> %s" % (line, owner, records[owner]))
        # if len(records) > 500: return records
    return records

def get_hinfo(cpu, os):
    # TODO: This should be done a cleaner way atleast so that the
    # code_str is meaningful
    try:
        ret = co.HinfoCode(cpu, os)
    except Errors.NotFoundError:
        global auto_hinfo_num
        auto_hinfo_num += 1
        ret = co.HinfoCode('hinfo_%i' % auto_hinfo_num, cpu, os)
        ret.insert()
    return ret

ip_cache = {}
def _get_ip(a_ip):
    logger.debug2("_get_ip(%s)" % a_ip)
    if not ip_cache.has_key(a_ip):
        ipnumber.clear()
        ipnumber.populate(a_ip)
        ipnumber.write_db()
        ip_cache[a_ip] = int(ipnumber.ip_number_id)
    return ip_cache[a_ip]
    
filter_warned = {}
def filter_name(name):
    if not name.endswith(zone_postfix):
        if name[-1] == '.':
            if not filter_warned.has_key(name):
                logger.warn("bad target postfix: %s" % name)
                filter_warned[name] = True
            return name
        return name+".uio.no."
    return name

def find_dns_owner(name, target_type=None):
    """Lookup a dns_owner by name, prioritying hosts/arecords/cnames
    before dns_owner if target_type is not set.

    Returns the corresponding object-type, and a (target_id, owner_id)
    tuple"""
    assert name == filter_name(name)  # assert that the parsing did this
    if target_type is None:
        if name2host.has_key(name):
            target_type = 'host'
        elif name2arecord_owner.has_key(name):
            target_type = 'a_record'
        elif name2cname.has_key(name):
            target_type = 'cname'
        elif name2dns_owner.has_key(name):
            target_type = 'dns_owner'

    if target_type == 'host':
        return host, name2host[name]
    elif target_type == 'a_record':
        return arecord, name2arecord_owner[name]
    elif target_type == 'cname':
        return cname, name2cname[name]
    elif target_type == 'dns_owner':
        return dnsowner, name2dns_owner[name]
    else:
        return None, None

def _make_foreign_owner(name):
    return _make_dns_owner(name)  # We no longger differenciate

def _make_dns_owner(name):
    dnsowner.clear()
    dnsowner.populate(name)
    dnsowner.write_db()
    owner_id = int(dnsowner.entity_id)
    name2dns_owner[name] = (owner_id, owner_id)
    return name2dns_owner[name]

a_ip_name_unique = {}
def pass_one(name, dta):
    if dta.has_key('A'):
        first_id = None
        for a in dta['A']:
            logger.debug("Adding A: %s" % name)
            arecord.clear()
            if not a_ip_name_unique.has_key((name, a[1])):
                a_ip_name_unique[(name, a[1])] = 1
                ip_ref = _get_ip(a[1])
                if not name2dns_owner.has_key(name):
                    _make_dns_owner(name)
                arecord.populate(name2dns_owner[name][1], ip_ref, ttl=dta['A'][0][0])
                arecord.write_db()
                # an A-record name is not unique
                name2arecord_owner[name] = (int(arecord.entity_id),
                                            int(arecord.dns_owner_id))
                default_revmap.setdefault(a[1], []).append(
                    {'name': name,
                     'id': int(arecord.entity_id)})
            else:
                # "tassenmac01  A       129.240.79.31" fantes 2 ganger i sonefila
                logger.warn("Duplicate A-record violation: %s->%s" % (a[0], a[1]))
        if dta.has_key('HINFO'):
            if len(dta['HINFO']) != 1:
                # we have many of these... don't want to see the warning
                #logger.warn("Many HINFO? %s -> %s" % (name, str(dta['HINFO'])))
                pass
            hinfo = get_hinfo(*dta['HINFO'][0][1:3])
            logger.debug2("HINFO %s -> %s" % (dta['HINFO'], hinfo))
            del dta['HINFO']
            host.clear()
            host.populate(name2dns_owner[name][1], hinfo, ttl=dta['A'][0][0])
            host.write_db()
            name2host[name] = (int(host.entity_id),
                               int(host.dns_owner_id))
                               
            # All existing TXT records are connected to host
            if dta.has_key('TXT'):
                if len(dta['TXT']) > 1:
                    logger.warn("Multiple TXT records for %s" % name)
                ttl, txt_val = dta['TXT'][0]
                dnsowner.add_general_dns_record(host.dns_owner_id, co.field_type_txt, ttl, txt_val)
                del dta['TXT']
        del dta['A']

def pass_two(name, dta):
    # We delay insertion of mx-records because we want the A-record to
    # exist first
    
    if dta.has_key('MX'):
        dta['MX'].sort()
        key = "-".join([ str(x) for x in dta['MX'] ])
        if not mx_targets.has_key(key):
            mx_name = "mx_target_%i" % (len(mx_targets) + 1)
            logger.debug("Creating %s" % mx_name)
            mx_set.clear()
            mx_set.populate(mx_name)
            mx_set.write_db()
            mx_targets[key] = int(mx_set.mx_set_id)
            for ttl, pri, target_name in dta['MX']:
                target_owner_obj, target_owner_ids = find_dns_owner(target_name)
                if target_owner_obj is None:
                    logger.warn("Creating foreign MX target %s" % target_name)
                    target_owner_ids = _make_foreign_owner(target_name)
                elif not isinstance(target_owner_obj, (
                    HostInfo.HostInfo, DnsOwner.DnsOwner,
                    ARecord.ARecord)):
                    logger.warn("Unsupported MX target %s" % target_owner_obj)
                    mx_targets[key] = None
                    continue
                mx_set.add_mx_set_member(ttl, pri, target_owner_ids[1])

        owner_obj, owner_ids = find_dns_owner(name)
        if owner_obj is None:
            logger.warn("MX for %s that is not A or host" % name)
            _make_foreign_owner(name)
            owner_obj, owner_ids = find_dns_owner(name)
        dnsowner.clear()
        dnsowner.find(owner_ids[1])
        dnsowner.mx_set_id = mx_targets[key]
        #logger.debug("TGT: %s for %s, %i" % (mx_targets[key], name, owner_ids[1]))
        dnsowner.write_db()
        del dta['MX']

    if dta.has_key('CNAME'):
        if len(dta['CNAME']) > 1:
            logger.warn("Too many CNAME in %s" % str(dta))
        cname_ttl, cname_target = dta['CNAME'][0]
        try:
            unused, target_owner_ids = find_dns_owner(cname_target, 'a_record')
        except KeyError:
            unused, target_owner_ids = find_dns_owner(cname_target)
            if target_owner_ids is None:
                target_owner_ids = _make_foreign_owner(cname_target)
            logger.warn("Unknown CNAME target, assuming foreign: %s" % cname_target)
        cname.clear()
        cname.populate(_make_dns_owner(name)[1], target_owner_ids[1], cname_ttl)
        cname.write_db()
        name2cname[name] = (int(cname.entity_id),
                            int(cname.cname_owner_id))
        del dta['CNAME']
    if dta.has_key('SRV'):
        unused, owner_ids = find_dns_owner(name)
        if owner_ids is None:
            owner_ids = _make_foreign_owner(name)

        for ttl, pri, weight, port, target_name in dta['SRV']:
            unused, target_owner_ids = find_dns_owner(target_name)
            if target_owner_ids is None:
                logger.warn("Creating foregin SRV target %s" % target_name)
                target_owner_ids = _make_foreign_owner(target_name)
            dnsowner.add_srv_record(owner_ids[1], pri, weight, port,
                                    ttl, target_owner_ids[1])
        del dta['SRV']
    if dta.has_key('contact') or dta.has_key('comment'):
        owner_obj, owner_ids = find_dns_owner(name)
        if not isinstance(owner_obj, (
            ARecord.ARecord, CNameRecord.CNameRecord, HostInfo.HostInfo)):
            logger.warn("What type is %s: %s ?" % (name, str(dta)))
        else:
            owner_obj.clear()
            owner_obj.find(owner_ids[0])
            if dta.has_key('contact'):
                owner_obj.add_entity_note(co.note_type_contact, dta['contact'])
                del dta['contact']
            if dta.has_key('comment'):
                owner_obj.add_entity_note(co.note_type_comment, dta['comment'])
                del dta['comment']

def records_to_db(r):
    logger.info("records_to_db()")
    for k in r.keys():
        if r[k].has_key('contact') and len(r[k].keys()) == 1:
            logger.warn("Contact for nothing: %s" % k)
            del(r[k])
    order = r.keys()  # Not really needed, but looks nice
    order.sort()
    for pass_num in range(1,3):
        # name has been through filter_name()
        for name in order:
            # logger.debug("%s -> %s" % (k, str(r[k])))
            logger.debug("Process %s" % name)
            if pass_num == 1:
                pass_one(name, r[name])
            elif pass_num == 2:
                logger.debug2("%s -> %s" % (name, str(r[name])))
                pass_two(name, r[name])
                for y in r[name]:
                    logger.warn("Unexpected rest (for %s): %s" % (name, str(r[name])))
    db.commit()
#    db.rollback()

def records_to_revdb(reverse_file):
    logger.info("records_to_revdb()")
    fail_warned = {}
    rev = {}
    parser.prepare_parse_revmap(reverse_file)
    while True:
        dta = parser.next_revmap()
        if not dta:
            break
        rev.setdefault(dta[0], []).append(dta[1])
    # Note that we do not support ips that expicitly shall not have a
    # reverse-map.
    
    # Handle entries that sohuld not have a reverse-map at all
    for ip in default_revmap.keys():   
        if not rev.has_key(ip):
            logger.warn("%s should not have a rev-map" % ip)
            ip_ref = _get_ip(ip)
            ipnumber.add_reverse_override(ip_ref, None)

    # Remove all entries with normal rev-maps
    for ip in rev.keys():   
        if len(rev[ip]) > 1:
            # This is illegal
            logger.error("rev file has multiple reverse for %s, using "
                         "default reversemap" % ip)
            del rev[ip]
            continue
        if not default_revmap.has_key(ip):
            logger.warn("rev-map for missing A-record %s" % ip)
            continue
        # Compare to default reversemap
        if len(default_revmap[ip]) > 1:
            logger.debug("multiple A-records for %s" % ip)
            continue
        name = rev[ip][0]
        if default_revmap[ip][0]['name'] != name:
            logger.info("rev-map for %s -> %s while A -> %s" % (
                ip, default_revmap[ip][0]['name'], name))
            continue
        # Has forward-map=reverse-map, no overide needed
        del rev[ip]

    # De som er igjen i rev setter revmap eskplisitt
    set_rev_map = {}
    for ip in rev.keys():
        name = rev[ip][0]
        owner_obj, owner_ids = find_dns_owner(name)
        if owner_obj is None:
            logger.warn("Foreign reverse-map owner: %s" % name)
            owner_ids = _make_foreign_owner(name)
        ip_ref = _get_ip(ip)
        ipnumber.add_reverse_override(ip_ref, owner_ids[1])
    db.commit()
        
def clear_db():
    logger.info("clear_db()")
    for tab in ('general_dns_record', 'reserved_host',
                'override_reversemap', 'other_mx', 'cname_record', 'dns_host_info',
                'a_record'):
        db.execute("delete from %s" % tab)
    db.execute("delete from entity_name where value_domain=:vd", {
        'vd': int(co.hostname_namespace)})
    db.commit()
    
def usage(exitcode=0):
    print """Usage: [options]

    Import an existing zone-file and corresponding reverse-map into
    Cerebrum.

    --help: help
    -h | --hosts filename: filename for hosts file
    -c | --clear: clear database
    -z | --zone filename: filename for zone file
    -r | --reverse filename: filename for reverse map
    -i | --import: start import of the above mentioned files
    --netgroups filename: filename with netgroups
    -n : start netgroup import

    Note that the part before the header_splitter will not be imported
    from the zone file or the reverse map.  That is because this part
    of the file contains special records like subdomains that we do
    not support.  Any CNAMES etc. should be moved below that line.

    Example:
      contrib/import_dns.py -z data/uio.no.orig -r data/129.240.orig -h data/hosts.orig -i
    """
    sys.exit(exitcode)

def main():
    try:
        opts, args = getopt.getopt(sys.argv[1:], 'ch:z:r:in', [
            'help', 'clear', 'zone=', 'reverse=', 'import',
            'hosts=', 'netgroups='])
    except getopt.GetoptError:
        usage(1)
    if not opts:
        usage(1)

    global parser
    parser = FileParsers()
    logger.debug("opts: %s" % str(opts))
    for opt, val in opts:
        if opt in ('--help', ):
            usage()
        elif opt in ('--clear', '-c'):
            clear_db()
        elif opt in ('--zone', '-z'):
            zone_file = val
        elif opt in ('--reverse', '-r'):
            reverse_file = val
        elif opt in ('--hosts', '-h'):
            hosts_file = val
        elif opt in ('--netgroups',):
            netgroup_file = val
        elif opt in ('--import', '-i'):
            recs = process_zone_file(zone_file)
            for name, comment in parser.parse_hosts_file(hosts_file).items():
                if not recs.has_key(name):
                    logger.warn("comment for unknown host %s" % name)
                else:
                    if recs[name].has_key('comment'):
                        recs[name]['comment'] += ' - '+comment
                        logger.warn("comment for %s in zone and hosts file" % name)
                    else:
                        recs[name]['comment'] = comment
            if recs.has_key('rom'):
                recs['rom']['HINFO'] = [[None, 'DELL-2650', 'LINUX']]
            records_to_db(recs)
            records_to_revdb(reverse_file)
        elif opt in ('-n',):
            import_netgroups(netgroup_file)

if __name__ == '__main__':
    main()

# arch-tag: 42732516-2596-4d60-b3d3-adc4443c9cad
